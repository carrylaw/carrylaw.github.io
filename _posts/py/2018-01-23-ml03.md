---
layout: post
title: Python机器学习之模型评估（ROC曲线）待完成
category: cpython
---

&emsp;&emsp;模型评估一直是数据建模中不可或缺的一环，评估指标的好坏直接关系到模型上线运用的情况。本文期望以最直观的方式告诉大家模型评估的相关指标，并利用python程序绘制令诸多同学疑惑的ROC曲线。**在此希望大家注意**：模型评估指标只能作为参考依据，在真正的项目实施过程中，还是需要针对具体业务具体分析。

分类模型（贝叶斯、决策树、SVM等）评估指标：
     
|评估指标  |具体描述  |sklearn对应函数  |  
|:----:|:----:|:----:|   
|Precision|精准度|from sklearn.metrics import precision_score|  
|Recall|召回率|from sklearn.metrics import recall_score|  
|F1|F1值|from sklearn.metrics import f1_score|  
|Confusion Matrix|混淆矩阵|from sklearn.metrics import confusion_matrix|  
|ROC|ROC曲线|from sklearn.metrics import roc|  
|AUC|ROC曲线下的面积|from sklearn.metrics import auc|  

回归模型（线性回归、非线性回归等）评估指标：  
   
|评估指标  |具体描述  |sklearn对应函数  |  
|:----:|:----:|:----:|  
|Mean Square Error(MSE/RMSE)|平均方差|from sklearn.metrics import mean_squared_error|  
|Absolute Error(MAE/RAE)|绝对误差|from sklearn.metrics import mean_absolute_error, median_absolute_error|  
|R-Squared(R^2)|R平方值|from sklearn.metrics import r2_score|     

## **<span style="color:#008B8B;">· 混淆矩阵、ROC曲线与AUC面积</span>**      
问题1：混淆矩阵是什么？    
回答1：混淆矩阵说简单一点就是预测的正例/反例与真实值之间的比例关系，该矩阵包括4个方面：       
         
|预测值 |真实值 |对应指标 |  
|:----:|:----:|:----:|
|正例|正例|True Positive(TP) |    
|正例|反例|False Positive(FP) |    
|反例|正例|True Negative(TN) |   
|反例|反例|False Negative(FN) |    

混淆矩阵图如下：    

<div align="center">
<img width="350" height="80" src="https://raw.githubusercontent.com/carrylaw/IMG/master/img_ml/sucai04.png" />
</div> 

由此计算TPR(True Positive Rate)：真实的正例中，被预测正确的比例，TPR = TP/(TP+FN)，FPR(False Positive Rate)：真实的反例中，被预测正确的比例，FPR = FP/(FP+TN)      

问题2：混淆矩阵、ROC曲线与AUC面积之间的关系？          
回答2：ROC曲线（Receiver Operation Characteristic）主要用于评估二分类模型的优劣，其计算基础便是混淆矩阵，其下方包围的面积为AUC（Area Under the Curve）。     






