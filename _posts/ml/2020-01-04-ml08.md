---
layout: post
title: Python编写一个神经网络算法
category: bml
---

&emsp;&emsp;之前写过[手工计算一个神经网络](https://carrylaw.github.io/bml/2019/11/26/ml07/)，那么如何用python编写一个神经网络呢？接下来便试着一步步实现。神经网络一共分为三块，初始网络、训练网络、查询网络，由此所编写的代码框架如下：
```python
# 神经网络框架
class neuralNetwork:
	# 初始网络
	def __int__():
		pass	
	# 训练网络
	def train():
		pass	
	# 查询网络
	def query():
		pass
```
## 完整的神经网络代码
```python
import scipy.special
import numpy

class neuralNetwork:
    # 初始网络
    def __init__(self,inputnodes,hiddennodes,outputnodes,learningrate):
        # 设置输入、输出、隐藏层
        self.inodes = inputnodes
        self.hnodes = hiddennodes
        self.onodes = outputnodes
        
        # 设置权重
        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5),(self.hnodes,self.inodes))
        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5),(self.onodes,self.hnodes))
        
        # 设置学习率
        self.lr = learningrate
        
        # 构建sigmiod函数
        self.activation_function = lambda x: scipy.special.expit(x)
        pass
    # 训练网络
    def train(self, inputs_list, targets_list):
        # 第一层输入
        inputs = numpy.array(inputs_list,ndmin=2).T
        targets= numpy.array(targets_list,ndmin=2).T

        # 隐藏层输入
        # X隐含 = W权重 * I输入
        hidden_inputs = numpy.dot(self.wih, inputs)
        # 隐藏层输出
        hidden_outputs = self.activation_function(hidden_inputs)       
        # 最终层输入
        final_inputs = numpy.dot(self.wih, hidden_outputs)
        # 最终层输出
        final_outputs = self.activation_function(final_inputs)
        
        # 误差值
        output_errors = targets- final_outputs
        # 反向传播 error隐藏 = WT隐藏 * error输出
        hidden_errors = numpy.dot(self.who.T,output_errors)
        
        # 传播隐藏到输出
        self.who = self.who + self.lr* numpy.dot((output_errors*final_outputs*(1.0-final_outputs)),numpy.transpose(hidden_outputs))
        # 传播输入到隐藏
        self.wih = self.wih + self.lr* numpy.dot((output_errors*hidden_outputs*(1.0-hidden_outputs)),numpy.transpose(inputs))

        pass
    
    # 输出网络
    def query(self, inputs_list):
        # 第一层输入
        inputs = numpy.array(inputs_list,ndmin=2).T

        # 隐藏层输入
        # X隐含 = W权重 * I输入
        hidden_inputs = numpy.dot(self.wih, inputs)
        # 隐藏层输出
        hidden_outputs = self.activation_function(hidden_inputs)
        
        # 最终层输入
        final_inputs = numpy.dot(self.wih, hidden_outputs)
        # 最终层输出
        final_outputs = self.activation_function(final_inputs)
        
        return final_outputs
```
## 训练这个神经网络，并输出相应结果
```python
# 输入层、隐含层、输出层节点数
input_nodes =3
hidden_nodes =3
output_nodes =3

# 学习率
learningrate = 0.3

# 训练一个神经网络
n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learningrate)

# 查询网络
n.query([1,0.5,-1.5])

# ====最终输出结果（数值可能不相同）====
array([[0.40511455],
       [0.40580834],
       [0.50113563]])
```